{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQqxE2XWqvbl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "\n",
        "def generate(q1,q2,n):\n",
        "\tn1=int(n/2)\n",
        "\tn2=int(n/2)\n",
        "\tQ1=np.full((n1,n1),q1)\n",
        "\tQ2=np.full((n2,n2),q2)\n",
        "\tS1=np.concatenate((Q1,Q2),axis=1)\n",
        "\tS2=np.concatenate((Q2,Q1),axis=1)\n",
        "\treturn (np.concatenate((S1,S2),axis=0))\n",
        "\n",
        "def statistic_max(D1,D2):\n",
        "\tA=D1.sum(axis=0)\n",
        "\tB=D2.sum(axis=0)\n",
        "\tC=np.absolute(np.triu(A,1).flatten()-np.triu(B,1).flatten())\n",
        "\treturn np.amax(C)\n",
        "\n",
        "def statistic_F6(D1,D2):\n",
        "\tsum=0\n",
        "\tmid=int(m/6)\n",
        "\tX1=D1[:mid].sum(axis=0)\n",
        "\tX2=D1[mid+1:2*mid].sum(axis=0)\n",
        "\tX3=D1[2*mid+1:3*mid].sum(axis=0)\n",
        "\tX4=D1[3*mid+1:4*mid].sum(axis=0)\n",
        "\tX5=D1[4*mid+1:5*mid].sum(axis=0)\n",
        "\tX6=D1[5*mid+1:6*mid].sum(axis=0)\n",
        "\tY1=D2[:mid].sum(axis=0)\n",
        "\tY2=D2[mid+1:2*mid].sum(axis=0)\n",
        "\tY3=D2[2*mid+1:3*mid].sum(axis=0)\n",
        "\tY4=D2[3*mid+1:4*mid].sum(axis=0)\n",
        "\tY5=D2[4*mid+1:5*mid].sum(axis=0)\n",
        "\tY6=D2[5*mid+1:6*mid].sum(axis=0)\n",
        "\tT1=np.triu(X1-Y1,1)\n",
        "\tT2=np.triu(X2-Y2,1)\n",
        "\tT3=np.triu(X3-Y3,1)\n",
        "\tT4=np.triu(X4-Y4,1)\n",
        "\tT5=np.triu(X5-Y5,1)\n",
        "\tT6=np.triu(X6-Y6,1)\n",
        "\treturn np.multiply(np.multiply(np.multiply(np.multiply(np.multiply(T1,T2),T3),T4),T5),T6).sum()\n",
        "\n",
        "def statistic_F4(D1,D2):\n",
        "\tsum=0\n",
        "\tmid=int((m+1)/4)\n",
        "\tX1=D1[:mid].sum(axis=0)\n",
        "\tX2=D1[mid+1:2*mid].sum(axis=0)\n",
        "\tX3=D1[2*mid+1:3*mid].sum(axis=0)\n",
        "\tX4=D1[3*mid+1:4*mid].sum(axis=0)\n",
        "\tY1=D2[:mid].sum(axis=0)\n",
        "\tY2=D2[mid+1:2*mid].sum(axis=0)\n",
        "\tY3=D2[2*mid+1:3*mid].sum(axis=0)\n",
        "\tY4=D2[3*mid+1:4*mid].sum(axis=0)\n",
        "\tT1=np.triu(X1-Y1,1)\n",
        "\tT2=np.triu(X2-Y2,1)\n",
        "\tT3=np.triu(X3-Y3,1)\n",
        "\tT4=np.triu(X4-Y4,1)\n",
        "\treturn np.multiply(np.multiply(np.multiply(T1,T2),T3),T4).sum()\n",
        "\n",
        "def statistic_F2(D1,D2):\n",
        "\tsum=0\n",
        "\tmid=int((m+1)/2)\n",
        "\tX1=D1[:mid].sum(axis=0)\n",
        "\tX2=D1[mid+1:].sum(axis=0)\n",
        "\tY1=D2[:mid].sum(axis=0)\n",
        "\tY2=D2[mid+1:].sum(axis=0)\n",
        "\tT1=np.triu(X1-Y1,1)\n",
        "\tT2=np.triu(X2-Y2,1)\n",
        "\treturn np.multiply(T1,T2).sum()\n",
        "\n",
        "def statistic_edge(D1,D2):\n",
        "\t\n",
        "\treturn np.triu(D1,0).sum()-np.triu(D2,0).sum()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eps=0.0\n",
        "repeat=100\n",
        "B=100\n",
        "n=100\n",
        "p=0.2\n",
        "m=36\n",
        "while p+eps<1.0:\n",
        "  P = np.full((n,n),p)\n",
        "  Q1= P+ eps\n",
        "  Q2= P+ np.power(n,0.5)*eps\n",
        "  Q3= P+ np.power(n,2.0/3)*eps\n",
        "\n",
        "\n",
        "  count_F2=0\n",
        "  count_F4=0\n",
        "  count_F6=0\n",
        "  for r in range(repeat):\n",
        "  \n",
        "    data1=np.array([np.random.binomial(1,P) for i in range(m)]) # m samples from P\n",
        "    data21=np.array([np.random.binomial(1,Q1) for i in range(m)]) # m samples from Q\n",
        "    data22=np.array([np.random.binomial(1,Q2) for i in range(m)]) # m samples from Q\n",
        "    data23=np.array([np.random.binomial(1,Q3) for i in range(m)]) # m samples from Q\n",
        "\n",
        "    stat_true_F2=statistic_F2(data1,data21)\n",
        "    stat_true_F4=statistic_F4(data1,data22)\n",
        "    stat_true_F6=statistic_F6(data1,data23)\n",
        "\n",
        "    \n",
        "    stats_F2=[]\n",
        "    stats_F4=[]\n",
        "    stats_F6=[]\n",
        "\n",
        "    for b in range(B):\n",
        "      temp=np.random.permutation(np.concatenate((data1,data21)))\n",
        "      X,Y=temp[0:m],temp[m:]\n",
        "\n",
        "      stats_F2.append(statistic_F2(X,Y))\n",
        "\n",
        "      temp=np.random.permutation(np.concatenate((data1,data22)))\n",
        "      X,Y=temp[0:m],temp[m:]\n",
        "      stats_F4.append(statistic_F4(X,Y))\n",
        "\n",
        "      temp=np.random.permutation(np.concatenate((data1,data23)))\n",
        "      X,Y=temp[0:m],temp[m:]\n",
        "      stats_F6.append(statistic_F6(X,Y))\n",
        "\n",
        "\n",
        "\n",
        "    cutoff_lower=np.quantile(stats_F2,0.025)\n",
        "    cutoff_upper=np.quantile(stats_F2,0.975)\n",
        "    if stat_true_F2<cutoff_lower or stat_true_F2>cutoff_upper:\n",
        "      count_F2+=1\n",
        "\n",
        "    cutoff_lower=np.quantile(stats_F4,0.025)\n",
        "    cutoff_upper=np.quantile(stats_F4,0.975)\n",
        "    if stat_true_F4<cutoff_lower or stat_true_F4>cutoff_upper:\n",
        "      count_F4+=1\n",
        "\n",
        "    cutoff_lower=np.quantile(stats_F6,0.025)\n",
        "    cutoff_upper=np.quantile(stats_F6,0.975)\n",
        "    if stat_true_F6<cutoff_lower or stat_true_F6>cutoff_upper:\n",
        "      count_F6+=1\n",
        "\n",
        "  print(eps,count_F2/repeat,count_F4/repeat,count_F6/repeat)\t\t\n",
        "  eps+=0.002"
      ],
      "metadata": {
        "id": "C6WFuoJrIwdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qslu27elXdEx"
      },
      "outputs": [],
      "source": [
        "for diff in [20]:#[1,10,50,100]:\n",
        "\teps=0.0\n",
        "\trepeat=100\n",
        "\tB=100\n",
        "\tn=100\n",
        "\tp=0.2\n",
        "\tm=36\n",
        "\twhile p+eps<1.0:\n",
        "\t\tP = np.full((n,n),p)\n",
        "\t\tQ=np.copy(P)\t\n",
        "\t\tQ[0][-diff:]+=eps\n",
        "\n",
        "\t\tcount_edge=0\n",
        "\t\tcount_F2=0\n",
        "\t\tcount_F4=0\n",
        "\t\tcount_F6=0\n",
        "\t\tcount_max=0\n",
        "\t\tfor r in range(repeat):\n",
        "\t\t\n",
        "\t\t\tdata1=np.array([np.random.binomial(1,P) for i in range(m)]) # m samples from P\n",
        "\t\t\tdata2=np.array([np.random.binomial(1,Q) for i in range(m)]) # m samples from Q\n",
        "\t\t\tstat_true_edge=statistic_edge(data1,data2)\n",
        "\t\t\tstat_true_F2=statistic_F2(data1,data2)\n",
        "\t\t\tstat_true_F4=statistic_F4(data1,data2)\n",
        "\t\t\tstat_true_F6=statistic_F6(data1,data2)\n",
        "\t\t\tstat_true_max=statistic_max(data1,data2)\n",
        "\n",
        "\t\t\tstats_edge=[]\n",
        "\t\t\tstats_F2=[]\n",
        "\t\t\tstats_F4=[]\n",
        "\t\t\tstats_F6=[]\n",
        "\t\t\tstats_max=[]\n",
        "\n",
        "\t\t\tfor b in range(B):\n",
        "\t\t\t\ttemp=np.random.permutation(np.concatenate((data1,data2)))\n",
        "\t\t\t\tX,Y=temp[0:m],temp[m:]\n",
        "\t\t\t\tstats_edge.append(statistic_edge(X,Y))\n",
        "\t\t\t\tstats_F2.append(statistic_F2(X,Y))\n",
        "\t\t\t\tstats_F4.append(statistic_F4(X,Y))\n",
        "\t\t\t\tstats_F6.append(statistic_F6(X,Y))\n",
        "\t\t\t\tstats_max.append(statistic_max(X,Y))\n",
        "\n",
        "\t\t\tcutoff_lower=np.quantile(stats_edge,0.025)\n",
        "\t\t\tcutoff_upper=np.quantile(stats_edge,0.975)\n",
        "\t\t\tif stat_true_edge<cutoff_lower or stat_true_edge>cutoff_upper:\n",
        "\t\t\t\tcount_edge+=1\n",
        "\n",
        "\t\t\tcutoff_lower=np.quantile(stats_F2,0.025)\n",
        "\t\t\tcutoff_upper=np.quantile(stats_F2,0.975)\n",
        "\t\t\tif stat_true_F2<cutoff_lower or stat_true_F2>cutoff_upper:\n",
        "\t\t\t\tcount_F2+=1\n",
        "\n",
        "\t\t\tcutoff_lower=np.quantile(stats_F4,0.025)\n",
        "\t\t\tcutoff_upper=np.quantile(stats_F4,0.975)\n",
        "\t\t\tif stat_true_F4<cutoff_lower or stat_true_F4>cutoff_upper:\n",
        "\t\t\t\tcount_F4+=1\n",
        "\n",
        "\t\t\tcutoff_lower=np.quantile(stats_F6,0.025)\n",
        "\t\t\tcutoff_upper=np.quantile(stats_F6,0.975)\n",
        "\t\t\tif stat_true_F6<cutoff_lower or stat_true_F6>cutoff_upper:\n",
        "\t\t\t\tcount_F6+=1\n",
        "\n",
        "\t\t\tcutoff_lower=np.quantile(stats_max,0.025)\n",
        "\t\t\tcutoff_upper=np.quantile(stats_max,0.975)\n",
        "\t\t\tif stat_true_max<cutoff_lower or stat_true_max>cutoff_upper:\n",
        "\t\t\t\tcount_max+=1\n",
        "\n",
        "\t\tprint(eps,count_edge/repeat,count_F2/repeat,count_F4/repeat,count_F6/repeat,count_max/repeat)\t\t\n",
        "\t\teps+=0.05"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NA-r37f4Xelh"
      },
      "outputs": [],
      "source": [
        "for diff in [1,10,50]:#,100]:\n",
        "\teps=0.0\n",
        "\trepeat=100\n",
        "\tB=100\n",
        "\tn=100\n",
        "\tp1=0.8\n",
        "\tp2=0.2\n",
        "\tm=32\n",
        "\twhile p2+eps<1.0:\n",
        "\t\tP = generate(p1,p2,n)#np.full((n,n),p)\n",
        "\t\tQ=np.copy(P)\t\n",
        "\t\tQ[0][-diff:]+=eps\n",
        "\n",
        "\t\tcount_edge=0\n",
        "\t\tcount_F2=0\n",
        "\t\tcount_F4=0\n",
        "\t\tcount_max=0\n",
        "\t\tfor r in range(repeat):\n",
        "\t\t\n",
        "\t\t\tdata1=np.array([np.random.binomial(1,P) for i in range(m)]) # m samples from P\n",
        "\t\t\tdata2=np.array([np.random.binomial(1,Q) for i in range(m)]) # m samples from Q\n",
        "\t\t\tstat_true_edge=statistic_edge(data1,data2)\n",
        "\t\t\tstat_true_F2=statistic_F2(data1,data2)\n",
        "\t\t\tstat_true_F4=statistic_F4(data1,data2)\n",
        "\t\t\tstat_true_max=statistic_max(data1,data2)\n",
        "\n",
        "\t\t\tstats_edge=[]\n",
        "\t\t\tstats_F2=[]\n",
        "\t\t\tstats_F4=[]\n",
        "\t\t\tstats_max=[]\n",
        "\n",
        "\t\t\tfor b in range(B):\n",
        "\t\t\t\ttemp=np.random.permutation(np.concatenate((data1,data2)))\n",
        "\t\t\t\tX,Y=temp[0:m],temp[m:]\n",
        "\t\t\t\tstats_edge.append(statistic_edge(X,Y))\n",
        "\t\t\t\tstats_F2.append(statistic_F2(X,Y))\n",
        "\t\t\t\tstats_F4.append(statistic_F4(X,Y))\n",
        "\t\t\t\tstats_max.append(statistic_max(X,Y))\n",
        "\n",
        "\t\t\tcutoff_lower=np.quantile(stats_edge,0.025)\n",
        "\t\t\tcutoff_upper=np.quantile(stats_edge,0.975)\n",
        "\t\t\tif stat_true_edge<cutoff_lower or stat_true_edge>cutoff_upper:\n",
        "\t\t\t\tcount_edge+=1\n",
        "\n",
        "\t\t\tcutoff_lower=np.quantile(stats_F2,0.025)\n",
        "\t\t\tcutoff_upper=np.quantile(stats_F2,0.975)\n",
        "\t\t\tif stat_true_F2<cutoff_lower or stat_true_F2>cutoff_upper:\n",
        "\t\t\t\tcount_F2+=1\n",
        "\n",
        "\t\t\tcutoff_lower=np.quantile(stats_F4,0.025)\n",
        "\t\t\tcutoff_upper=np.quantile(stats_F4,0.975)\n",
        "\t\t\tif stat_true_F4<cutoff_lower or stat_true_F4>cutoff_upper:\n",
        "\t\t\t\tcount_F4+=1\n",
        "\n",
        "\t\t\tcutoff_lower=np.quantile(stats_max,0.025)\n",
        "\t\t\tcutoff_upper=np.quantile(stats_max,0.975)\n",
        "\t\t\tif stat_true_max<cutoff_lower or stat_true_max>cutoff_upper:\n",
        "\t\t\t\tcount_max+=1\n",
        "\n",
        "\t\tprint(eps,count_edge/repeat,count_F2/repeat,count_F4/repeat,count_max/repeat)\t\t\n",
        "\t\teps+=0.05"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "voYtpW_amxNE"
      },
      "outputs": [],
      "source": [
        "def generate_beta(beta):\n",
        "\tn=len(beta)\n",
        "\tmat=np.zeros((n,n))\n",
        "\tfor i in range(n):\n",
        "\t\tfor j in range(n):\n",
        "\t\t\tmat[i][j]=np.exp(beta[i]+beta[j])/(1+np.exp(beta[i]+beta[j]))\n",
        "\treturn mat\n",
        "\n",
        "for diff in [10,50]:#,100]:\n",
        "\tprint(\"DIFFFFF\")\n",
        "\teps=0.0\n",
        "\trepeat=100\n",
        "\tB=100\n",
        "\tn=100\n",
        "\tbeta=np.random.normal(loc=0.0, scale=1.0, size=n)\n",
        "\tm=32\n",
        "\twhile eps<1.0:\n",
        "\t\tP = generate_beta(beta)#np.full((n,n),p)\n",
        "\t\tbeta_mod=beta.copy()\n",
        "\t\tbeta_mod[0]+=eps\n",
        "\t\tQ= generate_beta(beta_mod)\n",
        "\n",
        "\t\tcount_edge=0\n",
        "\t\tcount_F2=0\n",
        "\t\tcount_F4=0\n",
        "\t\tcount_max=0\n",
        "\t\tfor r in range(repeat):\n",
        "\t\t\n",
        "\t\t\tdata1=np.array([np.random.binomial(1,P) for i in range(m)]) # m samples from P\n",
        "\t\t\tdata2=np.array([np.random.binomial(1,Q) for i in range(m)]) # m samples from Q\n",
        "\t\t\tstat_true_edge=statistic_edge(data1,data2)\n",
        "\t\t\tstat_true_F2=statistic_F2(data1,data2)\n",
        "\t\t\tstat_true_F4=statistic_F4(data1,data2)\n",
        "\t\t\tstat_true_max=statistic_max(data1,data2)\n",
        "\n",
        "\t\t\tstats_edge=[]\n",
        "\t\t\tstats_F2=[]\n",
        "\t\t\tstats_F4=[]\n",
        "\t\t\tstats_max=[]\n",
        "\n",
        "\t\t\tfor b in range(B):\n",
        "\t\t\t\ttemp=np.random.permutation(np.concatenate((data1,data2)))\n",
        "\t\t\t\tX,Y=temp[0:m],temp[m:]\n",
        "\t\t\t\tstats_edge.append(statistic_edge(X,Y))\n",
        "\t\t\t\tstats_F2.append(statistic_F2(X,Y))\n",
        "\t\t\t\tstats_F4.append(statistic_F4(X,Y))\n",
        "\t\t\t\tstats_max.append(statistic_max(X,Y))\n",
        "\n",
        "\t\t\tcutoff_lower=np.quantile(stats_edge,0.025)\n",
        "\t\t\tcutoff_upper=np.quantile(stats_edge,0.975)\n",
        "\t\t\tif stat_true_edge<cutoff_lower or stat_true_edge>cutoff_upper:\n",
        "\t\t\t\tcount_edge+=1\n",
        "\n",
        "\t\t\tcutoff_lower=np.quantile(stats_F2,0.025)\n",
        "\t\t\tcutoff_upper=np.quantile(stats_F2,0.975)\n",
        "\t\t\tif stat_true_F2<cutoff_lower or stat_true_F2>cutoff_upper:\n",
        "\t\t\t\tcount_F2+=1\n",
        "\n",
        "\t\t\tcutoff_lower=np.quantile(stats_F4,0.025)\n",
        "\t\t\tcutoff_upper=np.quantile(stats_F4,0.975)\n",
        "\t\t\tif stat_true_F4<cutoff_lower or stat_true_F4>cutoff_upper:\n",
        "\t\t\t\tcount_F4+=1\n",
        "\n",
        "\t\t\tcutoff_lower=np.quantile(stats_max,0.025)\n",
        "\t\t\tcutoff_upper=np.quantile(stats_max,0.975)\n",
        "\t\t\tif stat_true_max<cutoff_lower or stat_true_max>cutoff_upper:\n",
        "\t\t\t\tcount_max+=1\n",
        "\n",
        "\t\tprint(eps,count_edge/repeat,count_F2/repeat,count_F4/repeat,count_max/repeat)\t\t\n",
        "\t\teps+=0.05"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}